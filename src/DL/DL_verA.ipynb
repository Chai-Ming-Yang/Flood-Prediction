{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UGq7APZYhHGP"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8,6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcG-tvu5zA0y"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "H-MzuWewr8tR",
        "outputId": "e1d6b49d-f49a-41cb-877f-36a243005616"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sl</th>\n",
              "      <th>Station_Names</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Max_Temp</th>\n",
              "      <th>Min_Temp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Relative_Humidity</th>\n",
              "      <th>Wind_Speed</th>\n",
              "      <th>Cloud_Coverage</th>\n",
              "      <th>Bright_Sunshine</th>\n",
              "      <th>Station_Number</th>\n",
              "      <th>X_COR</th>\n",
              "      <th>Y_COR</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Period</th>\n",
              "      <th>Flood?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Barisal</td>\n",
              "      <td>1949</td>\n",
              "      <td>1</td>\n",
              "      <td>29.4</td>\n",
              "      <td>12.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.453704</td>\n",
              "      <td>0.6</td>\n",
              "      <td>7.831915</td>\n",
              "      <td>41950</td>\n",
              "      <td>536809.8</td>\n",
              "      <td>510151.9</td>\n",
              "      <td>22.7</td>\n",
              "      <td>90.36</td>\n",
              "      <td>4</td>\n",
              "      <td>1949.01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Barisal</td>\n",
              "      <td>1949</td>\n",
              "      <td>2</td>\n",
              "      <td>33.9</td>\n",
              "      <td>15.2</td>\n",
              "      <td>9.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.659259</td>\n",
              "      <td>0.9</td>\n",
              "      <td>8.314894</td>\n",
              "      <td>41950</td>\n",
              "      <td>536809.8</td>\n",
              "      <td>510151.9</td>\n",
              "      <td>22.7</td>\n",
              "      <td>90.36</td>\n",
              "      <td>4</td>\n",
              "      <td>1949.02</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Barisal</td>\n",
              "      <td>1949</td>\n",
              "      <td>3</td>\n",
              "      <td>36.7</td>\n",
              "      <td>20.2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1.085185</td>\n",
              "      <td>1.5</td>\n",
              "      <td>8.131915</td>\n",
              "      <td>41950</td>\n",
              "      <td>536809.8</td>\n",
              "      <td>510151.9</td>\n",
              "      <td>22.7</td>\n",
              "      <td>90.36</td>\n",
              "      <td>4</td>\n",
              "      <td>1949.03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Barisal</td>\n",
              "      <td>1949</td>\n",
              "      <td>4</td>\n",
              "      <td>33.9</td>\n",
              "      <td>23.9</td>\n",
              "      <td>140.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>1.772222</td>\n",
              "      <td>3.9</td>\n",
              "      <td>8.219149</td>\n",
              "      <td>41950</td>\n",
              "      <td>536809.8</td>\n",
              "      <td>510151.9</td>\n",
              "      <td>22.7</td>\n",
              "      <td>90.36</td>\n",
              "      <td>4</td>\n",
              "      <td>1949.04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Barisal</td>\n",
              "      <td>1949</td>\n",
              "      <td>5</td>\n",
              "      <td>35.6</td>\n",
              "      <td>25.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1.703704</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.046809</td>\n",
              "      <td>41950</td>\n",
              "      <td>536809.8</td>\n",
              "      <td>510151.9</td>\n",
              "      <td>22.7</td>\n",
              "      <td>90.36</td>\n",
              "      <td>4</td>\n",
              "      <td>1949.05</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sl Station_Names  Year  Month  Max_Temp  Min_Temp  Rainfall  \\\n",
              "0   0       Barisal  1949      1      29.4      12.3       0.0   \n",
              "1   1       Barisal  1949      2      33.9      15.2       9.0   \n",
              "2   2       Barisal  1949      3      36.7      20.2       8.0   \n",
              "3   3       Barisal  1949      4      33.9      23.9     140.0   \n",
              "4   4       Barisal  1949      5      35.6      25.0     217.0   \n",
              "\n",
              "   Relative_Humidity  Wind_Speed  Cloud_Coverage  Bright_Sunshine  \\\n",
              "0               68.0    0.453704             0.6         7.831915   \n",
              "1               63.0    0.659259             0.9         8.314894   \n",
              "2               59.0    1.085185             1.5         8.131915   \n",
              "3               71.0    1.772222             3.9         8.219149   \n",
              "4               76.0    1.703704             4.1         7.046809   \n",
              "\n",
              "   Station_Number     X_COR     Y_COR  LATITUDE  LONGITUDE  ALT   Period  \\\n",
              "0           41950  536809.8  510151.9      22.7      90.36    4  1949.01   \n",
              "1           41950  536809.8  510151.9      22.7      90.36    4  1949.02   \n",
              "2           41950  536809.8  510151.9      22.7      90.36    4  1949.03   \n",
              "3           41950  536809.8  510151.9      22.7      90.36    4  1949.04   \n",
              "4           41950  536809.8  510151.9      22.7      90.36    4  1949.05   \n",
              "\n",
              "   Flood?  \n",
              "0     NaN  \n",
              "1     NaN  \n",
              "2     NaN  \n",
              "3     NaN  \n",
              "4     NaN  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('..\\..\\datasets\\A_Flood_Dataset.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QrZSeKLQsL5p"
      },
      "outputs": [],
      "source": [
        "df = data.drop(columns=['Sl', 'Station_Names', 'Station_Number', 'X_COR', 'Y_COR', 'Period'])\n",
        "df = df.drop(columns=['LATITUDE', 'LONGITUDE'])\n",
        "df['Flood?'] = df['Flood?'].fillna(0).astype(int)\n",
        "df.sort_values(by=['Year','Month'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y48C_YEWsMXi",
        "outputId": "d0447872-606d-4b49-eb71-275764b6aa9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df shape : (20544, 11) \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20544 entries, 1356 to 20543\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Year               20544 non-null  int64  \n",
            " 1   Month              20544 non-null  int64  \n",
            " 2   Max_Temp           20544 non-null  float64\n",
            " 3   Min_Temp           20544 non-null  float64\n",
            " 4   Rainfall           20544 non-null  float64\n",
            " 5   Relative_Humidity  20544 non-null  float64\n",
            " 6   Wind_Speed         20544 non-null  float64\n",
            " 7   Cloud_Coverage     20544 non-null  float64\n",
            " 8   Bright_Sunshine    20544 non-null  float64\n",
            " 9   ALT                20544 non-null  int64  \n",
            " 10  Flood?             20544 non-null  int64  \n",
            "dtypes: float64(7), int64(4)\n",
            "memory usage: 1.9 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"df shape :\", df.shape, \"\\n\")\n",
        "df.info()\n",
        "# df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-HeOZMcs_PN"
      },
      "source": [
        "# Data Splitting & Window Sliding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1jRPcRAtsMhz"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Year', 'Flood?'])\n",
        "Y = df['Flood?']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tKh1tJ-2a0d_"
      },
      "outputs": [],
      "source": [
        "\"\"\" SLIDING WINDOW \"\"\"\n",
        "WINDOW_SIZE = 5\n",
        "def create_dataset(X, Y):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - WINDOW_SIZE):\n",
        "        v = X[i:(i + WINDOW_SIZE)]\n",
        "        Xs.append(v)\n",
        "        ys.append(Y.iloc[i + WINDOW_SIZE])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_seq, Y_seq = create_dataset(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y9tXkWOyuDed"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, Y_seq, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gctLZSLqsMrO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Reshape for scaling ---\n",
        "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
        "X_val_reshaped = X_val.reshape(-1, X_val.shape[-1])\n",
        "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
        "\n",
        "# --- Initialize and fit scaler ---\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "\n",
        "# --- Transform validation and test data ---\n",
        "X_val_scaled = scaler.transform(X_val_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# --- Reshape back to original 3D shape ---\n",
        "X_train_seq = X_train_scaled.reshape(X_train.shape)\n",
        "X_val_seq = X_val_scaled.reshape(X_val.shape)\n",
        "X_test_seq = X_test_scaled.reshape(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9IhosYQsMwx",
        "outputId": "973309bb-0ad9-49d4-e243-118e16abeee1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(None, 5, 9)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "def build_lstm_model(learning_rate=0.0001):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(WINDOW_SIZE, X.shape[1])))\n",
        "  model.add(LSTM(64, return_sequences=True))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(LSTM(32, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(LSTM(16, return_sequences=False))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = Adam(learning_rate=learning_rate, clipvalue=1.0)\n",
        "  loss = BinaryCrossentropy()\n",
        "  model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_lstm_model()\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "  monitor='val_loss',\n",
        "  factor=0.5,\n",
        "  patience=5,\n",
        "  min_lr=1e-5,\n",
        "  verbose=1\n",
        ")\n",
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Sf__wtsNDf",
        "outputId": "e97b6aff-089d-4949-9d80-90c32a9306a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5983 - loss: 0.6587 - val_accuracy: 0.7780 - val_loss: 0.5272 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4429 - val_accuracy: 0.8558 - val_loss: 0.3364 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8433 - loss: 0.3490 - val_accuracy: 0.8571 - val_loss: 0.3113 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8405 - loss: 0.3227 - val_accuracy: 0.8571 - val_loss: 0.3090 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.3083 - val_accuracy: 0.8522 - val_loss: 0.3073 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8440 - loss: 0.3038 - val_accuracy: 0.8601 - val_loss: 0.3056 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.3034 - val_accuracy: 0.8534 - val_loss: 0.3049 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8480 - loss: 0.3016 - val_accuracy: 0.8516 - val_loss: 0.3047 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8483 - loss: 0.3000 - val_accuracy: 0.8595 - val_loss: 0.3020 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8487 - loss: 0.2977 - val_accuracy: 0.8558 - val_loss: 0.3017 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8512 - loss: 0.2992 - val_accuracy: 0.8528 - val_loss: 0.3033 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.2989 - val_accuracy: 0.8564 - val_loss: 0.3009 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8502 - loss: 0.2956 - val_accuracy: 0.8564 - val_loss: 0.3010 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8481 - loss: 0.2968 - val_accuracy: 0.8571 - val_loss: 0.3000 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8479 - loss: 0.2959 - val_accuracy: 0.8564 - val_loss: 0.2992 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8498 - loss: 0.2953 - val_accuracy: 0.8571 - val_loss: 0.2989 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.2959 - val_accuracy: 0.8571 - val_loss: 0.2983 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.2951 - val_accuracy: 0.8577 - val_loss: 0.2977 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8513 - loss: 0.2937 - val_accuracy: 0.8528 - val_loss: 0.2979 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 0.2955 - val_accuracy: 0.8558 - val_loss: 0.2968 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8491 - loss: 0.2936 - val_accuracy: 0.8558 - val_loss: 0.2969 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8523 - loss: 0.2908 - val_accuracy: 0.8552 - val_loss: 0.2961 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8528 - loss: 0.2914 - val_accuracy: 0.8564 - val_loss: 0.2960 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8507 - loss: 0.2914 - val_accuracy: 0.8528 - val_loss: 0.2959 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.2912 - val_accuracy: 0.8540 - val_loss: 0.2952 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8510 - loss: 0.2931 - val_accuracy: 0.8558 - val_loss: 0.2962 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8482 - loss: 0.2933 - val_accuracy: 0.8528 - val_loss: 0.2959 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8508 - loss: 0.2920 - val_accuracy: 0.8552 - val_loss: 0.2957 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.2923 - val_accuracy: 0.8558 - val_loss: 0.2959 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.2908 - val_accuracy: 0.8540 - val_loss: 0.2947 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 0.2921 - val_accuracy: 0.8546 - val_loss: 0.2948 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8520 - loss: 0.2914 - val_accuracy: 0.8534 - val_loss: 0.2945 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8513 - loss: 0.2911 - val_accuracy: 0.8540 - val_loss: 0.2941 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8511 - loss: 0.2912 - val_accuracy: 0.8540 - val_loss: 0.2941 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8527 - loss: 0.2912 - val_accuracy: 0.8546 - val_loss: 0.2944 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8527 - loss: 0.2894 - val_accuracy: 0.8522 - val_loss: 0.2940 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.2902 - val_accuracy: 0.8534 - val_loss: 0.2935 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8537 - loss: 0.2887 - val_accuracy: 0.8558 - val_loss: 0.2943 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8509 - loss: 0.2890 - val_accuracy: 0.8558 - val_loss: 0.2936 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.2893 - val_accuracy: 0.8534 - val_loss: 0.2934 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8514 - loss: 0.2879 - val_accuracy: 0.8522 - val_loss: 0.2936 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.2909 - val_accuracy: 0.8522 - val_loss: 0.2931 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.2876 - val_accuracy: 0.8564 - val_loss: 0.2938 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.2897 - val_accuracy: 0.8564 - val_loss: 0.2934 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8506 - loss: 0.2889 - val_accuracy: 0.8558 - val_loss: 0.2930 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8538 - loss: 0.2897 - val_accuracy: 0.8564 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.2893 - val_accuracy: 0.8564 - val_loss: 0.2928 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8516 - loss: 0.2889 - val_accuracy: 0.8558 - val_loss: 0.2935 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8546 - loss: 0.2895 - val_accuracy: 0.8577 - val_loss: 0.2925 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8528 - loss: 0.2892 - val_accuracy: 0.8589 - val_loss: 0.2929 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8550 - loss: 0.2894 - val_accuracy: 0.8577 - val_loss: 0.2924 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8542 - loss: 0.2874 - val_accuracy: 0.8504 - val_loss: 0.2923 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8530 - loss: 0.2885 - val_accuracy: 0.8571 - val_loss: 0.2931 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8537 - loss: 0.2866 - val_accuracy: 0.8534 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.2905 - val_accuracy: 0.8534 - val_loss: 0.2921 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8558 - loss: 0.2865 - val_accuracy: 0.8546 - val_loss: 0.2918 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.2842 - val_accuracy: 0.8564 - val_loss: 0.2926 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.2886 - val_accuracy: 0.8552 - val_loss: 0.2925 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.2872 - val_accuracy: 0.8540 - val_loss: 0.2918 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8545 - loss: 0.2892 - val_accuracy: 0.8577 - val_loss: 0.2925 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m231/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8553 - loss: 0.2875\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8553 - loss: 0.2875 - val_accuracy: 0.8528 - val_loss: 0.2927 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8557 - loss: 0.2881 - val_accuracy: 0.8571 - val_loss: 0.2924 - learning_rate: 5.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8556 - loss: 0.2865 - val_accuracy: 0.8498 - val_loss: 0.2921 - learning_rate: 5.0000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8576 - loss: 0.2854 - val_accuracy: 0.8540 - val_loss: 0.2925 - learning_rate: 5.0000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.2874 - val_accuracy: 0.8571 - val_loss: 0.2923 - learning_rate: 5.0000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m228/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8567 - loss: 0.2873\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8566 - loss: 0.2874 - val_accuracy: 0.8564 - val_loss: 0.2927 - learning_rate: 5.0000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8537 - loss: 0.2871 - val_accuracy: 0.8577 - val_loss: 0.2923 - learning_rate: 2.5000e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8551 - loss: 0.2860 - val_accuracy: 0.8546 - val_loss: 0.2921 - learning_rate: 2.5000e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8562 - loss: 0.2857 - val_accuracy: 0.8564 - val_loss: 0.2928 - learning_rate: 2.5000e-05\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "history = model.fit(\n",
        "    X_train_seq, y_train,\n",
        "    validation_data=(X_val_seq, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fKW4deeLv6aN"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(history, key):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history[key], label=key)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(key)\n",
        "  plt.legend([key, 'val_'+key])\n",
        "  plt.title(f\"Training and Validation {key}\")\n",
        "  plt.show()\n",
        "\n",
        "plot_history(history, 'val_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WB-JZXgiv6gG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Accuracy :  0.8439629990262901\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90      3206\n",
            "           1       0.67      0.58      0.62       902\n",
            "\n",
            "    accuracy                           0.84      4108\n",
            "   macro avg       0.78      0.75      0.76      4108\n",
            "weighted avg       0.84      0.84      0.84      4108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test_seq)\n",
        "y_pred = (y_pred >= 0.5).astype(int)\n",
        "\n",
        "print(\"Accuracy : \", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ws0FLP6g3GkU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "      <th>y_pred_count</th>\n",
              "      <th>y_test_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3331</td>\n",
              "      <td>3206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>777</td>\n",
              "      <td>902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Value  y_pred_count  y_test_count\n",
              "0      0          3331          3206\n",
              "1      1           777           902"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Flatten the arrays before creating Series\n",
        "y_pred_flat = y_pred.ravel()  # or use y_pred.flatten()\n",
        "y_test_flat = y_test.ravel()  # or use y_test.flatten()\n",
        "\n",
        "# Create DataFrames and get value counts in one step\n",
        "y_pred_counts = pd.Series(y_pred_flat).value_counts().reset_index(name='y_pred_count')\n",
        "y_test_counts = pd.Series(y_test_flat).value_counts().reset_index(name='y_test_count')\n",
        "\n",
        "# Rename 'index' to 'Value' for both DataFrames before merging\n",
        "y_pred_counts.rename(columns={'index': 'Value'}, inplace=True)\n",
        "y_test_counts.rename(columns={'index': 'Value'}, inplace=True)\n",
        "\n",
        "# Merge the counts and align them by 'Value'\n",
        "merged_counts = pd.merge(y_pred_counts, y_test_counts, on='Value', how='outer')\n",
        "\n",
        "# Display the result\n",
        "merged_counts.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UaasiIYCv6wX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('trained_model', exist_ok=True)\n",
        "model.save(os.path.join('trained_model', 'DL_verA_trained.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHmQLHu_QwI9"
      },
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rUQ7HWCzLApD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Fold 1...\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "--- Fold 1 Results ---\n",
            "Accuracy :  0.8326029798422436\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90      2757\n",
            "           1       0.59      0.44      0.51       666\n",
            "\n",
            "    accuracy                           0.83      3423\n",
            "   macro avg       0.73      0.68      0.70      3423\n",
            "weighted avg       0.82      0.83      0.82      3423\n",
            "\n",
            "--------------------\n",
            "Processing Fold 2...\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step\n",
            "--- Fold 2 Results ---\n",
            "Accuracy :  0.8290972830850132\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.90      2764\n",
            "           1       0.56      0.50      0.53       659\n",
            "\n",
            "    accuracy                           0.83      3423\n",
            "   macro avg       0.72      0.70      0.71      3423\n",
            "weighted avg       0.82      0.83      0.83      3423\n",
            "\n",
            "--------------------\n",
            "Processing Fold 3...\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "--- Fold 3 Results ---\n",
            "Accuracy :  0.8483786152497809\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.90      2735\n",
            "           1       0.61      0.68      0.64       688\n",
            "\n",
            "    accuracy                           0.85      3423\n",
            "   macro avg       0.76      0.79      0.77      3423\n",
            "weighted avg       0.86      0.85      0.85      3423\n",
            "\n",
            "--------------------\n",
            "Processing Fold 4...\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "--- Fold 4 Results ---\n",
            "Accuracy :  0.855097867367806\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91      2670\n",
            "           1       0.67      0.67      0.67       753\n",
            "\n",
            "    accuracy                           0.86      3423\n",
            "   macro avg       0.79      0.79      0.79      3423\n",
            "weighted avg       0.85      0.86      0.85      3423\n",
            "\n",
            "--------------------\n",
            "Processing Fold 5...\n",
            "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "--- Fold 5 Results ---\n",
            "Accuracy :  0.8361086765994742\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90      2679\n",
            "           1       0.65      0.55      0.59       744\n",
            "\n",
            "    accuracy                           0.84      3423\n",
            "   macro avg       0.76      0.73      0.74      3423\n",
            "weighted avg       0.83      0.84      0.83      3423\n",
            "\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5) # You can adjust the number of splits\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_classification_reports = []\n",
        "fold = 0\n",
        "for train_index, test_index in tscv.split(X_seq):\n",
        "    fold += 1\n",
        "    print(f\"Processing Fold {fold}...\")\n",
        "\n",
        "    # Split data into train and test for this fold\n",
        "    X_train_fold, X_test_fold = X_seq[train_index], X_seq[test_index]\n",
        "    y_train_fold, y_test_fold = Y_seq[train_index], Y_seq[test_index]\n",
        "\n",
        "    # Further split the training fold into train and validation\n",
        "    # We maintain the time series nature, so no shuffling\n",
        "    # Split size for validation can be adjusted\n",
        "    val_size = int(len(X_train_fold) * 0.1)\n",
        "    X_train_inner, X_val_fold = X_train_fold[:-val_size], X_train_fold[-val_size:]\n",
        "    y_train_inner, y_val_fold = y_train_fold[:-val_size], y_train_fold[-val_size:]\n",
        "\n",
        "    # Reshape for scaling\n",
        "    X_train_inner_reshaped = X_train_inner.reshape(-1, X_train_inner.shape[-1])\n",
        "    X_val_fold_reshaped = X_val_fold.reshape(-1, X_val_fold.shape[-1])\n",
        "    X_test_fold_reshaped = X_test_fold.reshape(-1, X_test_fold.shape[-1])\n",
        "\n",
        "    # Initialize and fit scaler on the training data of this fold\n",
        "    scaler_fold = MinMaxScaler()\n",
        "    X_train_inner_scaled = scaler_fold.fit_transform(X_train_inner_reshaped)\n",
        "\n",
        "    # Transform validation and test data using the scaler fitted on the training data\n",
        "    X_val_fold_scaled = scaler_fold.transform(X_val_fold_reshaped)\n",
        "    X_test_fold_scaled = scaler_fold.transform(X_test_fold_reshaped)\n",
        "\n",
        "    # Reshape back to original 3D shape\n",
        "    X_train_inner_seq = X_train_inner_scaled.reshape(X_train_inner.shape)\n",
        "    X_val_fold_seq = X_val_fold_scaled.reshape(X_val_fold.shape)\n",
        "    X_test_fold_seq = X_test_fold_scaled.reshape(X_test_fold.shape)\n",
        "\n",
        "\n",
        "    # Build and compile a fresh model for each fold\n",
        "    model_fold = build_lstm_model()\n",
        "\n",
        "    # Define callbacks\n",
        "    lr_scheduler_fold = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-5,\n",
        "        verbose=0 # Set verbose to 0 for cleaner output\n",
        "    )\n",
        "    early_stopping_fold = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    history_fold = model_fold.fit(\n",
        "        X_train_inner_seq, y_train_inner,\n",
        "        validation_data=(X_val_fold_seq, y_val_fold),\n",
        "        epochs=100,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping_fold, lr_scheduler_fold],\n",
        "        verbose=0 # Set verbose to 0 for cleaner output\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the test set of this fold\n",
        "    y_pred_fold = model_fold.predict(X_test_fold_seq)\n",
        "    y_pred_fold = (y_pred_fold >= 0.5).astype(int)\n",
        "\n",
        "    # Store accuracy & classification Report\n",
        "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
        "    fold_accuracies.append(accuracy)\n",
        "    report_dict = classification_report(y_test_fold, y_pred_fold, output_dict=True)\n",
        "    fold_classification_reports.append(report_dict)\n",
        "\n",
        "    # Print evaluation metrics for the fold\n",
        "    print(f\"--- Fold {fold} Results ---\")\n",
        "    print(\"Accuracy : \", accuracy)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test_fold, y_pred_fold))\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5ns-UYq1UBfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Cross-Validation Summary ---\n",
            "Average Accuracy  : 0.8403\n",
            "Standard Deviation: 0.0099\n",
            "\n",
            "Average Classification Report:\n",
            "              precision    recall  f1-score      support\n",
            "0              0.891933  0.909957  0.900634  2721.000000\n",
            "1              0.616891  0.567254  0.588252   702.000000\n",
            "accuracy       0.840257  0.840257  0.840257     0.840257\n",
            "macro avg      0.754412  0.738605  0.744443  3423.000000\n",
            "weighted avg   0.835901  0.840257  0.837067  3423.000000\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Cross-Validation Summary ---\")\n",
        "print(f\"Average Accuracy  : {np.mean(fold_accuracies):.4f}\")\n",
        "print(f\"Standard Deviation: {np.std(fold_accuracies):.4f}\")\n",
        "\n",
        "# Convert each report dict into a DataFrame\n",
        "reports_dfs = [pd.DataFrame(report).transpose() for report in fold_classification_reports]\n",
        "# Concatenate all DataFrames into one with a MultiIndex (fold index, class label)\n",
        "all_reports_df = pd.concat(reports_dfs, keys=range(len(reports_dfs)), axis=0)\n",
        "# Group by class label (level=1) and compute mean of metrics\n",
        "mean_report_df = all_reports_df.groupby(level=1).mean()\n",
        "\n",
        "print(\"\\nAverage Classification Report:\")\n",
        "print(mean_report_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
